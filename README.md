# Agente RAG Contextual con scraping

Sistema de IA para procesar documentaci√≥n t√©cnica desde una URL y responder preguntas complejas de forma conversacional. El agente est√° orquestado con LangGraph y se expone a trav√©s de una API RESTful con una interfaz de usuario web.

## üìã Descripci√≥n

Este proyecto implementa un agente de IA avanzado capaz de ingestar, comprender y razonar sobre documentaci√≥n t√©cnica en l√≠nea. La soluci√≥n completa permite:

- **Endpoint p√∫blico** para iniciar el procesamiento as√≠ncrono de una URL.
- **L√≥gica de agente no lineal** con an√°lisis de intenci√≥n y enrutamiento condicional.
- **Sistema de RAG (Retrieval-Augmented Generation)** para basar las respuestas en el contenido del documento.
- **Memoria conversacional** para entender preguntas de seguimiento.
- **Panel de usuario interactivo** para gestionar sesiones y chatear con el agente.

## üöÄ Caracter√≠sticas Principales

### ‚úÖ Funcionalidades Implementadas

#### 1. **Procesamiento de Documentaci√≥n**
- `POST /api/v1/process-documentation/`
- Proceso **as√≠ncrono** que se ejecuta en segundo plano.
- Opci√≥n de elegir entre un **scraper est√°ndar** y un m√©todo avanzado con IA (**Jina Reader**).
- El texto extra√≠do pasa por una **segmentaci√≥n sem√°ntica inteligente** para preservar el contexto.
- Los fragmentos (chunks) se vectorizan y almacenan en una base de datos vectorial.

#### 2. **L√≥gica del Agente con LangGraph**
- **An√°lisis de Intenci√≥n**: El agente clasifica cada pregunta del usuario para entender su prop√≥sito (`rag_query`, `code_query`, `memory_query`, etc.).
- **Enrutamiento Condicional**: Basado en la intenci√≥n, el grafo dirige la solicitud a la ruta m√°s adecuada (RAG, an√°lisis de c√≥digo, respuesta conversacional).
- **Memoria Conversacional**: La memoria nativa del modelo (gestionada a trav√©s de un objeto de sesi√≥n) se mantiene en el estado del grafo, permitiendo al agente recordar interacciones previas.
- **Formateo de C√≥digo**: Un nodo final revisa las respuestas y se asegura de que cualquier fragmento de c√≥digo est√© correctamente formateado en Markdown.

#### 3. **Interfaz de Usuario y API**
- **Interfaz Web**: Un frontend completo para iniciar el procesamiento, ver sesiones anteriores y chatear de forma interactiva.
- **API RESTful**: Endpoints bien definidos para todas las funcionalidades, permitiendo la integraci√≥n con otros sistemas.
- **Persistencia de Datos**: El estado del procesamiento y el historial de cada chat se almacenan de forma persistente en Firebase Firestore.
***
## üèõÔ∏è Arquitectura de la Soluci√≥n

La aplicaci√≥n se divide en tres capas principales: Frontend, Backend (API) y el Agente de IA.

1.  **Frontend**: Una aplicaci√≥n de una sola p√°gina (SPA) construida con HTML, CSS y JavaScript vainilla.
2.  **Backend (API Flask)**: Una API RESTful que expone los endpoints y orquesta las llamadas al agente.
3.  **Agente de IA (LangGraph)**: El cerebro del sistema. Un grafo de estados que gestiona la l√≥gica de la conversaci√≥n.
4.  **Bases de Datos**:
    * **Firebase Firestore**: Almacena el historial de conversaciones y el estado del procesamiento.
    * **ChromaDB**: Base de datos vectorial para almacenar los embeddings y realizar b√∫squedas de similitud.

## Diagrama del Grafo del Agente (LangGraph)
```
graph TD
    A[Input: Pregunta] --> B{1. Analizar Intenci√≥n};
    B --> C{2. Router Condicional};
    C -- "rag_query" --> D[3a. Recuperar Contexto];
    D --> E[4a. Generar Respuesta RAG];
    E --> F[5. Formatear C√≥digo];
    C -- "code_query" --> G[3b. Analizar C√≥digo];
    G --> F;
    C -- "greeting / memory_query" --> H[3c. Respuesta Conversacional];
    C -- "clarification" --> I[3d. Pedir Clarificaci√≥n];
    F --> Z[Output: Respuesta Final];
```
## Modelo de Datos en Firestore
La base de datos se estructura en una colecci√≥n chats, donde cada documento representa una sesi√≥n de conversaci√≥n.
```
chats (Colecci√≥n)
‚îî‚îÄ‚îÄ 9a8b7c6d-e5f4-3g2h-1i0j (Documento - ID de Chat √önico)
    ‚îú‚îÄ‚îÄ source_url: "https://requests.readthedocs.io/..." (String)
    ‚îú‚îÄ‚îÄ status: "Completado" (String)
    ‚îú‚îÄ‚îÄ created_at: Timestamp
    ‚îú‚îÄ‚îÄ chunk_count: 5 (Number)
    ‚îî‚îÄ‚îÄ history: (Array)
        ‚îî‚îÄ‚îÄ [0] (Objeto/Mapa)
            ‚îú‚îÄ‚îÄ role: "user" (String)
            ‚îú‚îÄ‚îÄ content: "Que hace Indra?" (String)
            ‚îî‚îÄ‚îÄ timestamp: "2025-08-15T22:15:30.123Z" (String)
```

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Lenguaje**: Python 3.11
- **Framework Backend**: Flask
- **Framework del Agente**: LangGraph
- **Modelo de Lenguaje (LLM)**: Google Gemini 1.5 Flash
- **Base de Datos (Estado/Historial)**: Firebase Firestore
- **Base de Datos Vectorial**: ChromaDB
- **Procesamiento NLP**: NLTK, Sentence-Transformers

## üì¶ Instalaci√≥n

### Prerrequisitos
- Python 3.11+
- Git
- Un entorno virtual (recomendado)

### Configuraci√≥n Local

1.  **Clonar el repositorio**
    ```bash
    git clone <url-del-repositorio>
    cd <nombre-del-repositorio>
    ```

2.  **Crear y activar el entorno virtual**
    ```bash
    # Windows
    python -m venv venv
    .\venv\Scripts\activate
    
    # macOS / Linux
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instalar dependencias**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configurar credenciales y variables de entorno**
    * **Google AI (Gemini)**:
        1.  Obt√©n tu clave de API desde [Google AI Studio](https://aistudio.google.com/).
        2.  Crea un archivo `.env` en la ra√≠z del proyecto.
        3.  A√±ade la clave al archivo: `GOOGLE_API_KEY="TU_CLAVE_DE_API"`

    * **Firebase**:
        1.  Crea un proyecto en la [Consola de Firebase](https://console.firebase.google.com/) y activa **Firestore Database**.
        2.  En `Project settings > Service accounts`, genera una nueva clave privada.
        3.  Renombra el archivo JSON descargado a `firebase-credentials.json` y col√≥calo en la ra√≠z del proyecto.

5.  **Descargar paquete de NLTK**
    Abre una consola de Python (`python`) y ejecuta:
    ```python
    import nltk
    nltk.download('punkt')
    ```

6.  **Ejecutar el servidor de desarrollo**
    ```bash
    python app.py
    ```
    La aplicaci√≥n estar√° disponible en `http://127.0.0.1:5000`.

## üì° API Endpoints

| M√©todo | Endpoint | Descripci√≥n | Autenticaci√≥n |
|---|---|---|---|
| `POST` | `/api/v1/process-documentation/` | Inicia el procesamiento as√≠ncrono de una URL | No requerida |
| `GET` | `/api/v1/processing-status/{id}/` | Consulta el estado de un procesamiento | No requerida |
| `POST` | `/api/v1/chat/{id}/` | Env√≠a un mensaje al chat (s√≠ncrono) | No requerida |
| `GET` | `/api/v1/chat-history/{id}/` | Obtiene el historial de un chat | No requerida |
| `GET` | `/api/v1/chats/` | Lista todas las sesiones de chat creadas | No requerida |

## üß™ Ejemplos de Uso (Postman)

Aunque la aplicaci√≥n est√° dise√±ada para ser usada a trav√©s de su interfaz web, la API es completamente funcional con herramientas como Postman.

### Crear Solicitud de Procesamiento

* **M√©todo**: `POST`
* **URL**: `http://127.0.0.1:5000/api/v1/process-documentation`
* **Body**: `raw`, `JSON`
    ```json
    {
        "url": "[https://langchain-ai.github.io/langgraph/concepts/](https://langchain-ai.github.io/langgraph/concepts/)",
        "method": "jina"
    }
    ```
* **Respuesta**: Confirmaci√≥n inmediata con `chatId` y estado `"En progreso"`.


### Chatear con el Agente

* **M√©todo**: `POST`
* **URL**: `http://127.0.0.1:5000/api/v1/chat/<tu-chat-id>`
* **Body**: `raw`, `JSON`
    ```json
    {
        "question": "¬øQu√© es el estado en LangGraph?"
    }
    ```
* **Respuesta**: Un objeto JSON con la respuesta final del agente.

## üíª Uso de la Interfaz Web

La forma m√°s sencilla de interactuar con el agente es a trav√©s de la interfaz web integrada. Una vez que la aplicaci√≥n est√© corriendo, abre tu navegador y ve a la siguiente URL:

**URL LOCAL**: **[http://127.0.0.1:5000](http://127.0.0.1:5000)**
**URL DESPLEGADO EN GCP**: **[http://127.0.0.1:5000](http://127.0.0.1:5000)**

### Flujo de Uso

1.  **Procesar un Documento Nuevo**:
    * En la pantalla principal, ver√°s una secci√≥n para introducir una URL.
    * Pega la URL de la documentaci√≥n t√©cnica que quieres analizar y haz clic en **"Procesar Documentaci√≥n"**.
    * Aparecer√° un di√°logo preguntando el m√©todo de extracci√≥n:
        * **Est√°ndar**: Usa el scraper b√°sico.
        * **Con IA (Jina)**: Usa el servicio avanzado de Jina Reader para una extracci√≥n m√°s limpia (recomendado).
    * La interfaz te mostrar√° el estado "Procesando...". Una vez que termine, el chat se activar√°.

2.  **Continuar una Sesi√≥n Anterior**:
    * La p√°gina principal lista todas las documentaciones que han sido procesadas previamente.
    * Para cada una, tienes dos opciones:
        * **Ver Historial**: Carga la conversaci√≥n anterior en la ventana de chat para revisarla.
        * **Iniciar Chat**: Te lleva a la ventana de chat para continuar la conversaci√≥n donde la dejaste.

3.  **Chatear con el Agente**:
    * Una vez en la ventana de chat, escribe tus preguntas en el campo de texto y presiona "Enviar" o la tecla Enter.
    * La respuesta del agente aparecer√° en la ventana. Puedes tener una conversaci√≥n fluida, haciendo preguntas de seguimiento o cambiando de tema.


## üß† L√≥gica del Agente Inteligente (LangGraph)

El n√∫cleo del proyecto es un grafo de estados que permite al agente tomar decisiones complejas.

### Flujo de Razonamiento del Agente

1.  **An√°lisis de Intenci√≥n**: Al recibir una pregunta, el primer nodo utiliza el LLM y el historial de la conversaci√≥n para clasificar la intenci√≥n del usuario (ej. `rag_query`, `code_query`, `memory_query`).
2.  **Enrutamiento Condicional**: Un enrutador dirige el flujo al camino m√°s apropiado seg√∫n la intenci√≥n detectada. Esto evita procesos innecesarios, como hacer una b√∫squeda vectorial para un simple "hola".
3.  **Ejecuci√≥n de la Ruta**:
    * **Ruta RAG**: Recupera fragmentos de texto relevantes de ChromaDB y los usa para generar una respuesta basada en la fuente.
    * **Ruta de C√≥digo**: Utiliza un prompt especializado para analizar o explicar fragmentos de c√≥digo.
    * **Ruta Conversacional**: Responde directamente usando la memoria de la conversaci√≥n para preguntas de seguimiento o saludos.
4.  **Formateo de C√≥digo**: Antes de finalizar, un nodo especializado se asegura de que cualquier c√≥digo en la respuesta est√© correctamente formateado en Markdown, mejorando la legibilidad.
5.  **Respuesta Final**: El estado final del grafo contiene la respuesta pulida que se env√≠a al usuario.

## üèóÔ∏è Estructura del Proyecto
```
agente-documentacion/
‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îî‚îÄ‚îÄ graph.py           # L√≥gica del agente con LangGraph
‚îú‚îÄ‚îÄ processing/
‚îÇ   ‚îú‚îÄ‚îÄ chunking.py        # Segmentaci√≥n sem√°ntica
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py         # Scraper est√°ndar
‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py    # Interacci√≥n con ChromaDB
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html         # Frontend todo-en-uno
‚îú‚îÄ‚îÄ .env                   # Variables de entorno (local)
‚îú‚îÄ‚îÄ app.py                 # Servidor Flask y API Endpoints
‚îú‚îÄ‚îÄ firebase-credentials.json # Clave de servicio de Firebase
‚îî‚îÄ‚îÄ requirements.txt
```

## ‚ö†Ô∏è Problemas Comunes

1.  **Error `onnxruntime` al iniciar**:
    * **Causa**: Discrepancia entre el entorno virtual de la terminal y el int√©rprete de Python del editor (ej. VS Code).
    * **Soluci√≥n**: Aseg√∫rate de que tu editor est√© configurado para usar el int√©rprete de `.\venv\Scripts\python.exe`. Ejecuta `python -m pip install --upgrade --force-reinstall chromadb` para asegurar las dependencias.

2.  **Error `LookupError: Resource punkt not found`**:
    * **Causa**: Faltan los datos del tokenizador de NLTK.
    * **Soluci√≥n**: Ejecuta el paso 5 de la instalaci√≥n para descargar los datos necesarios.

3.  **Error `403 Insufficient authentication scopes`**:
    * **Causa**: La API de Google (Vertex AI) no est√° habilitada en el proyecto de Google Cloud asociado a tu clave.
    * **Soluci√≥n**: Ve a la consola de Google Cloud, selecciona el proyecto correcto, busca "Vertex AI API" y haz clic en "Habilitar".

## üìÑ Licencia

Este proyecto es propiedad de Jhon Medina. Todos los derechos reservados.

## üìû Soporte

- **Desarrollador**: [Jhon Medina]
- **Email**: [jhonstmedinav@gmail.com]