# Agente RAG Contextual con scraping

Sistema de IA para procesar documentaciÃ³n tÃ©cnica desde una URL y responder preguntas complejas de forma conversacional. El agente estÃ¡ orquestado con LangGraph y se expone a travÃ©s de una API RESTful con una interfaz de usuario web.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un agente de IA avanzado capaz de ingestar, comprender y razonar sobre documentaciÃ³n tÃ©cnica en lÃ­nea. La soluciÃ³n completa permite:

- **Endpoint pÃºblico** para iniciar el procesamiento asÃ­ncrono de una URL.
- **LÃ³gica de agente no lineal** con anÃ¡lisis de intenciÃ³n y enrutamiento condicional.
- **Sistema de RAG (Retrieval-Augmented Generation)** para basar las respuestas en el contenido del documento.
- **Memoria conversacional** para entender preguntas de seguimiento.
- **Panel de usuario interactivo** para gestionar sesiones y chatear con el agente.

## ğŸš€ CaracterÃ­sticas Principales

### âœ… Funcionalidades Implementadas

#### 1. **Procesamiento de DocumentaciÃ³n**
- `POST /api/v1/process-documentation/`
- Proceso **asÃ­ncrono** que se ejecuta en segundo plano.
- OpciÃ³n de elegir entre un **scraper estÃ¡ndar** y un mÃ©todo avanzado con IA (**Jina Reader**).
- El texto extraÃ­do pasa por una **segmentaciÃ³n semÃ¡ntica inteligente** para preservar el contexto.
- Los fragmentos (chunks) se vectorizan y almacenan en una base de datos vectorial.

#### 2. **LÃ³gica del Agente con LangGraph**
- **AnÃ¡lisis de IntenciÃ³n**: El agente clasifica cada pregunta del usuario para entender su propÃ³sito (`rag_query`, `code_query`, `memory_query`, etc.).
- **Enrutamiento Condicional**: Basado en la intenciÃ³n, el grafo dirige la solicitud a la ruta mÃ¡s adecuada (RAG, anÃ¡lisis de cÃ³digo, respuesta conversacional).
- **Memoria Conversacional**: La memoria nativa del modelo (gestionada a travÃ©s de un objeto de sesiÃ³n) se mantiene en el estado del grafo, permitiendo al agente recordar interacciones previas.
- **Formateo de CÃ³digo**: Un nodo final revisa las respuestas y se asegura de que cualquier fragmento de cÃ³digo estÃ© correctamente formateado en Markdown.

#### 3. **Interfaz de Usuario y API**
- **Interfaz Web**: Un frontend completo para iniciar el procesamiento, ver sesiones anteriores y chatear de forma interactiva.
- **API RESTful**: Endpoints bien definidos para todas las funcionalidades, permitiendo la integraciÃ³n con otros sistemas.
- **Persistencia de Datos**: El estado del procesamiento y el historial de cada chat se almacenan de forma persistente en Firebase Firestore.
***
## ğŸ›ï¸ Arquitectura de la SoluciÃ³n

La aplicaciÃ³n se divide en tres capas principales: Frontend, Backend (API) y el Agente de IA.

1.  **Frontend**: Una aplicaciÃ³n de una sola pÃ¡gina (SPA) construida con HTML, CSS y JavaScript vainilla.
2.  **Backend (API Flask)**: Una API RESTful que expone los endpoints y orquesta las llamadas al agente.
3.  **Agente de IA (LangGraph)**: El cerebro del sistema. Un grafo de estados que gestiona la lÃ³gica de la conversaciÃ³n.
4.  **Bases de Datos**:
    * **Firebase Firestore**: Almacena el historial de conversaciones y el estado del procesamiento.
    * **ChromaDB**: Base de datos vectorial para almacenar los embeddings y realizar bÃºsquedas de similitud.

## Diagrama del Grafo del Agente (LangGraph)
```
graph TD
    A[Input: Pregunta] --> B{1. Analizar IntenciÃ³n};
    B --> C{2. Router Condicional};
    C -- "rag_query" --> D[3a. Recuperar Contexto];
    D --> E[4a. Generar Respuesta RAG];
    E --> F[5. Formatear CÃ³digo];
    C -- "code_query" --> G[3b. Analizar CÃ³digo];
    G --> F;
    C -- "greeting / memory_query" --> H[3c. Respuesta Conversacional];
    C -- "clarification" --> I[3d. Pedir ClarificaciÃ³n];
    F --> Z[Output: Respuesta Final];
```
## Modelo de Datos en Firestore
La base de datos se estructura en una colecciÃ³n chats, donde cada documento representa una sesiÃ³n de conversaciÃ³n.
```
chats (ColecciÃ³n)
â””â”€â”€ 9a8b7c6d-e5f4-3g2h-1i0j (Documento - ID de Chat Ãšnico)
    â”œâ”€â”€ source_url: "https://requests.readthedocs.io/..." (String)
    â”œâ”€â”€ status: "Completado" (String)
    â”œâ”€â”€ created_at: Timestamp
    â”œâ”€â”€ chunk_count: 5 (Number)
    â””â”€â”€ history: (Array)
        â””â”€â”€ [0] (Objeto/Mapa)
            â”œâ”€â”€ role: "user" (String)
            â”œâ”€â”€ content: "Que hace Indra?" (String)
            â””â”€â”€ timestamp: "2025-08-15T22:15:30.123Z" (String)
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Lenguaje**: Python 3.11
- **Framework Backend**: Flask
- **Framework del Agente**: LangGraph
- **Modelo de Lenguaje (LLM)**: Google Gemini 1.5 Flash
- **Base de Datos (Estado/Historial)**: Firebase Firestore
- **Base de Datos Vectorial**: ChromaDB
- **Procesamiento NLP**: NLTK, Sentence-Transformers

## ğŸ“¦ InstalaciÃ³n

### Prerrequisitos
- Python 3.11+
- Git
- Un entorno virtual (recomendado)

### ConfiguraciÃ³n Local

1.  **Clonar el repositorio**
    ```bash
    git clone <url-del-repositorio>
    cd <nombre-del-repositorio>
    ```

2.  **Crear y activar el entorno virtual**
    ```bash
    # Windows
    python -m venv venv
    .\venv\Scripts\activate
    
    # macOS / Linux
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instalar dependencias**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configurar credenciales y variables de entorno**
    * **Google AI (Gemini)**:
        1.  ObtÃ©n tu clave de API desde [Google AI Studio](https://aistudio.google.com/).
        2.  Crea un archivo `.env` en la raÃ­z del proyecto.
        3.  AÃ±ade la clave al archivo: `GOOGLE_API_KEY="TU_CLAVE_DE_API"`

    * **Firebase**:
        1.  Crea un proyecto en la [Consola de Firebase](https://console.firebase.google.com/) y activa **Firestore Database**.
        2.  En `Project settings > Service accounts`, genera una nueva clave privada.
        3.  Renombra el archivo JSON descargado a `firebase-credentials.json` y colÃ³calo en la raÃ­z del proyecto.

5.  **Descargar paquete de NLTK**
    Abre una consola de Python (`python`) y ejecuta:
    ```python
    import nltk
    nltk.download('punkt')
    ```

6.  **Ejecutar el servidor de desarrollo**
    ```bash
    python app.py
    ```
    La aplicaciÃ³n estarÃ¡ disponible en `http://127.0.0.1:5000`.

## ğŸ“¡ API Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n | AutenticaciÃ³n |
|---|---|---|---|
| `POST` | `/api/v1/process-documentation/` | Inicia el procesamiento asÃ­ncrono de una URL | No requerida |
| `GET` | `/api/v1/processing-status/{id}/` | Consulta el estado de un procesamiento | No requerida |
| `POST` | `/api/v1/chat/{id}/` | EnvÃ­a un mensaje al chat (sÃ­ncrono) | No requerida |
| `GET` | `/api/v1/chat-history/{id}/` | Obtiene el historial de un chat | No requerida |
| `GET` | `/api/v1/chats/` | Lista todas las sesiones de chat creadas | No requerida |

## ğŸ§ª Ejemplos de Uso (Postman)

Aunque la aplicaciÃ³n estÃ¡ diseÃ±ada para ser usada a travÃ©s de su interfaz web, la API es completamente funcional con herramientas como Postman.

### Crear Solicitud de Procesamiento

* **MÃ©todo**: `POST`
* **URL**: `http://127.0.0.1:5000/api/v1/process-documentation`
* **Body**: `raw`, `JSON`
    ```json
    {
        "url": "[https://langchain-ai.github.io/langgraph/concepts/](https://langchain-ai.github.io/langgraph/concepts/)",
        "method": "jina"
    }
    ```
* **Respuesta**: ConfirmaciÃ³n inmediata con `chatId` y estado `"En progreso"`.


### Chatear con el Agente

* **MÃ©todo**: `POST`
* **URL**: `http://127.0.0.1:5000/api/v1/chat/<tu-chat-id>`
* **Body**: `raw`, `JSON`
    ```json
    {
        "question": "Â¿QuÃ© es el estado en LangGraph?"
    }
    ```
* **Respuesta**: Un objeto JSON con la respuesta final del agente.

## ğŸ’» Uso de la Interfaz Web

La forma mÃ¡s sencilla de interactuar con el agente es a travÃ©s de la interfaz web integrada. Una vez que la aplicaciÃ³n estÃ© corriendo, abre tu navegador y ve a la siguiente URL:

**URL LOCAL**: **[http://127.0.0.1:5000](http://127.0.0.1:5000)**
**URL DESPLEGADO EN GCP**: **[http://127.0.0.1:5000](http://127.0.0.1:5000)**

### Flujo de Uso

1.  **Procesar un Documento Nuevo**:
    * En la pantalla principal, verÃ¡s una secciÃ³n para introducir una URL.
    * Pega la URL de la documentaciÃ³n tÃ©cnica que quieres analizar y haz clic en **"Procesar DocumentaciÃ³n"**.
    * AparecerÃ¡ un diÃ¡logo preguntando el mÃ©todo de extracciÃ³n:
        * **EstÃ¡ndar**: Usa el scraper bÃ¡sico.
        * **Con IA (Jina)**: Usa el servicio avanzado de Jina Reader para una extracciÃ³n mÃ¡s limpia (recomendado).
    * La interfaz te mostrarÃ¡ el estado "Procesando...". Una vez que termine, el chat se activarÃ¡.

2.  **Continuar una SesiÃ³n Anterior**:
    * La pÃ¡gina principal lista todas las documentaciones que han sido procesadas previamente.
    * Para cada una, tienes dos opciones:
        * **Ver Historial**: Carga la conversaciÃ³n anterior en la ventana de chat para revisarla.
        * **Iniciar Chat**: Te lleva a la ventana de chat para continuar la conversaciÃ³n donde la dejaste.

3.  **Chatear con el Agente**:
    * Una vez en la ventana de chat, escribe tus preguntas en el campo de texto y presiona "Enviar" o la tecla Enter.
    * La respuesta del agente aparecerÃ¡ en la ventana. Puedes tener una conversaciÃ³n fluida, haciendo preguntas de seguimiento o cambiando de tema.


## ğŸ§  LÃ³gica del Agente Inteligente (LangGraph)

El nÃºcleo del proyecto es un grafo de estados que permite al agente tomar decisiones complejas.

### Flujo de Razonamiento del Agente

1.  **AnÃ¡lisis de IntenciÃ³n**: Al recibir una pregunta, el primer nodo utiliza el LLM y el historial de la conversaciÃ³n para clasificar la intenciÃ³n del usuario (ej. `rag_query`, `code_query`, `memory_query`).
2.  **Enrutamiento Condicional**: Un enrutador dirige el flujo al camino mÃ¡s apropiado segÃºn la intenciÃ³n detectada. Esto evita procesos innecesarios, como hacer una bÃºsqueda vectorial para un simple "hola".
3.  **EjecuciÃ³n de la Ruta**:
    * **Ruta RAG**: Recupera fragmentos de texto relevantes de ChromaDB y los usa para generar una respuesta basada en la fuente.
    * **Ruta de CÃ³digo**: Utiliza un prompt especializado para analizar o explicar fragmentos de cÃ³digo.
    * **Ruta Conversacional**: Responde directamente usando la memoria de la conversaciÃ³n para preguntas de seguimiento o saludos.
4.  **Formateo de CÃ³digo**: Antes de finalizar, un nodo especializado se asegura de que cualquier cÃ³digo en la respuesta estÃ© correctamente formateado en Markdown, mejorando la legibilidad.
5.  **Respuesta Final**: El estado final del grafo contiene la respuesta pulida que se envÃ­a al usuario.

## ğŸ—ï¸ Estructura del Proyecto
```
agente-documentacion/
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ graph.py           # LÃ³gica del agente con LangGraph
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ chunking.py        # SegmentaciÃ³n semÃ¡ntica
â”‚   â”œâ”€â”€ scraper.py         # Scraper estÃ¡ndar
â”‚   â””â”€â”€ vector_store.py    # InteracciÃ³n con ChromaDB
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Frontend todo-en-uno
â”œâ”€â”€ .env                   # Variables de entorno (local)
â”œâ”€â”€ app.py                 # Servidor Flask y API Endpoints
â”œâ”€â”€ firebase-credentials.json # Clave de servicio de Firebase
â””â”€â”€ requirements.txt
```

## âš ï¸ Problemas Comunes

1.  **Error `onnxruntime` al iniciar**:
    * **Causa**: Discrepancia entre el entorno virtual de la terminal y el intÃ©rprete de Python del editor (ej. VS Code).
    * **SoluciÃ³n**: AsegÃºrate de que tu editor estÃ© configurado para usar el intÃ©rprete de `.\venv\Scripts\python.exe`. Ejecuta `python -m pip install --upgrade --force-reinstall chromadb` para asegurar las dependencias.

2.  **Error `LookupError: Resource punkt not found`**:
    * **Causa**: Faltan los datos del tokenizador de NLTK.
    * **SoluciÃ³n**: Ejecuta el paso 5 de la instalaciÃ³n para descargar los datos necesarios.

3.  **Error `403 Insufficient authentication scopes`**:
    * **Causa**: La API de Google (Vertex AI) no estÃ¡ habilitada en el proyecto de Google Cloud asociado a tu clave.
    * **SoluciÃ³n**: Ve a la consola de Google Cloud, selecciona el proyecto correcto, busca "Vertex AI API" y haz clic en "Habilitar".

## ğŸ“„ Licencia

Este proyecto es propiedad de Jhon Medina. Todos los derechos reservados.

## ğŸ“ Soporte

- **Desarrollador**: [Jhon Medina]
- **Email**: [jhonstmedinav@gmail.com]